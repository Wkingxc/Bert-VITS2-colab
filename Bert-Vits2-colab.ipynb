{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT1ZvJc4-Nks",
        "outputId": "d040d77f-26b7-4950-9e88-c58414331e39"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Wkingxc/Bert-Vits2-Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsDwhUbw8nkt",
        "outputId": "5114bdc1-187b-43ac-8b44-d988b416b609"
      },
      "outputs": [],
      "source": [
        "# 创建训练文件夹\n",
        "%cd Bert-Vits2-Colab\n",
        "c_name = \"Xier\" # 填写角色名称\n",
        "!mkdir -p \"./Data/$c_name/filelists\"\n",
        "!mkdir -p \"./Data/$c_name/models\"\n",
        "!mkdir -p \"./Data/$c_name/raw/$c_name\"\n",
        "!mkdir -p \"./Data/$c_name/wavs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9SgDIpKH91ba"
      },
      "outputs": [],
      "source": [
        "# 从谷歌硬盘拷贝音频和台词文件\n",
        "# c_voice = \"Xier.zip\"\n",
        "# !cp ../drive/MyDrive/$c_voice ./Data/$c_name/raw/$c_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKDi9zGmRZps",
        "outputId": "65eda286-a4ef-4701-fb15-87f70950f83e"
      },
      "outputs": [],
      "source": [
        "# 将音频文件和lab台词解压到 Data/角色名/raw/ 角色名里\n",
        "!unzip ./Data/$c_name/raw/$c_name/$c_voice -d ./Data/$c_name/raw/$c_name/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atRCCFpoTd6E",
        "outputId": "6cb4d6a5-27ba-4350-b1b3-f50be6184b2d"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKmJqXLVAsny",
        "outputId": "0f96ac7e-f163-4514-ac63-d1d12044edfc"
      },
      "outputs": [],
      "source": [
        "!echo \"=====下载 bert=====\"\n",
        "!wget -P ./bert/chinese-roberta-wwm-ext-large/ https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
        "!wget -P ./bert/deberta-v2-large-japanese-char-wwm/ https://huggingface.co/ku-nlp/deberta-v2-large-japanese-char-wwm/resolve/main/pytorch_model.bin\n",
        "!wget -P ./bert/deberta-v3-large/ https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.bin\n",
        "!wget -P ./bert/deberta-v3-large/ https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.generator.bin\n",
        "!wget -P ./bert/deberta-v3-large/ https://huggingface.co/microsoft/deberta-v3-large/resolve/main/spm.model\n",
        "\n",
        "!wget -P ./bert/Erlangshen-MegatronBert-1.3B-Chinese https://huggingface.co/IDEA-CCNL/Erlangshen-UniMC-MegatronBERT-1.3B-Chinese/resolve/main/pytorch_model.bin\n",
        "\n",
        "!echo \"====下载slm====\"\n",
        "!wget -P ./slm/wavlm-base-plus/ https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin\n",
        "!wget -P ./emotional/clap-htsat-fused https://huggingface.co/laion/clap-htsat-fused/resolve/main/pytorch_model.bin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5SVZKwfJWJC",
        "outputId": "e88c0da3-e28d-4bc3-a32d-28d192241a72"
      },
      "outputs": [],
      "source": [
        "# 下面正式开始训练步骤\n",
        "# !nvidia-smi\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OljFOvDPUZjE",
        "outputId": "2e62db6e-3000-42ad-dcb4-16c0654bfb98"
      },
      "outputs": [],
      "source": [
        "!python trans_wav_lab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGxyMLLOI4Uz",
        "outputId": "f316618d-0266-49d0-fb22-2eb668d6cad7"
      },
      "outputs": [],
      "source": [
        "!python preprocess_text.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOAg3awaLSKn",
        "outputId": "0fdc780e-b062-466f-d047-7194158f8982"
      },
      "outputs": [],
      "source": [
        "!python bert_gen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTLoqtUSMgTO",
        "outputId": "03fdd9d9-6035-4a78-b1b4-e74ec6bd9960"
      },
      "outputs": [],
      "source": [
        "!python clap_gen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PObA0WqsVT-v",
        "outputId": "5c4549bd-7276-4c79-b551-a2043bcaa8cb"
      },
      "outputs": [],
      "source": [
        "# 下载底模进行训练\n",
        "!wget -P \"./Data/$c_name/models/\" https://huggingface.co/guiyun/Bert-VITS2-chinese/resolve/main/D_0.pth\n",
        "!wget -P \"./Data/$c_name/models/\" https://huggingface.co/guiyun/Bert-VITS2-chinese/resolve/main/G_0.pth\n",
        "!wget -P \"./Data/$c_name/models/\" https://huggingface.co/guiyun/Bert-VITS2-chinese/resolve/main/WD_0.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kneNJH-iUhOS",
        "outputId": "254bf0ba-f6cf-4832-8306-e42cdb14f1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-06 16:57:34.748101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-06 16:57:34.748159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-06 16:57:34.757121: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-06 16:57:34.777128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-06 16:57:36.688315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "加载config中的配置0\n",
            "加载config中的配置localhost\n",
            "加载config中的配置10086\n",
            "加载config中的配置0\n",
            "加载config中的配置1\n",
            "加载环境变量 \n",
            "MASTER_ADDR: localhost,\n",
            "MASTER_PORT: 10086,\n",
            "WORLD_SIZE: 1,\n",
            "RANK: 0,\n",
            "LOCAL_RANK: 0\n",
            "\u001b[32m01-06 16:57:42\u001b[0m \u001b[1mINFO     \u001b[0m| data_utils.py:65 | Init dataset...\n",
            "100% 515/515 [00:00<00:00, 45724.40it/s]\n",
            "\u001b[32m01-06 16:57:42\u001b[0m \u001b[1mINFO     \u001b[0m| data_utils.py:80 | skipped: 0, total: 515\n",
            "\u001b[32m01-06 16:57:42\u001b[0m \u001b[1mINFO     \u001b[0m| data_utils.py:65 | Init dataset...\n",
            "100% 4/4 [00:00<00:00, 23172.95it/s]\n",
            "\u001b[32m01-06 16:57:42\u001b[0m \u001b[1mINFO     \u001b[0m| data_utils.py:80 | skipped: 0, total: 4\n",
            "Using noise scaled MAS for VITS2\n",
            "INFO:models:Loaded checkpoint 'Data/Xier/models/WD_600.pth' (iteration 7)\n",
            "INFO:models:Loaded checkpoint 'Data/Xier/models/G_600.pth' (iteration 7)\n",
            "INFO:models:Loaded checkpoint 'Data/Xier/models/D_600.pth' (iteration 7)\n",
            "******************检测到模型存在，epoch为 7，gloabl step为 600*********************\n",
            "Some weights of the model checkpoint at ./slm/wavlm-base-plus were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of WavLMModel were not initialized from the model checkpoint at ./slm/wavlm-base-plus and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0% 0/129 [00:00<?, ?it/s]INFO:models:Train Epoch: 7 [0%]\n",
            "INFO:models:[2.9597127437591553, 2.408641815185547, 0.9229468107223511, 18.922237396240234, 2.3539187908172607, 1.8047362565994263, 600, 9.9996e-05]\n",
            "Evaluating ...\n",
            "INFO:models:Saving model and optimizer state at iteration 7 to Data/Xier/models/G_600.pth\n",
            "INFO:models:Saving model and optimizer state at iteration 7 to Data/Xier/models/D_600.pth\n",
            "INFO:models:Saving model and optimizer state at iteration 7 to Data/Xier/models/WD_600.pth\n",
            "100% 129/129 [03:28<00:00,  1.61s/it]\n",
            "INFO:models:====> Epoch: 7\n",
            " 55% 71/129 [01:48<01:29,  1.55s/it]INFO:models:Train Epoch: 8 [55%]\n",
            "INFO:models:[2.969026565551758, 1.6245393753051758, 0.6767745614051819, 15.305644989013672, 2.1343374252319336, 2.0975732803344727, 800, 9.999200016e-05]\n",
            "Evaluating ...\n",
            "INFO:models:Saving model and optimizer state at iteration 8 to Data/Xier/models/G_800.pth\n",
            "INFO:models:Saving model and optimizer state at iteration 8 to Data/Xier/models/D_800.pth\n",
            "INFO:models:Saving model and optimizer state at iteration 8 to Data/Xier/models/WD_800.pth\n",
            "100% 129/129 [03:36<00:00,  1.68s/it]\n",
            "INFO:models:====> Epoch: 8\n",
            " 49% 63/129 [01:42<01:45,  1.61s/it]"
          ]
        }
      ],
      "source": [
        "!python train_ms.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
